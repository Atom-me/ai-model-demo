"""
æŸ¥è¯¢AIHubMixæ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
"""
import os
import sys
import requests
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.config import Config

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def get_aihubmix_models():
    """æŸ¥è¯¢AIHubMixæ”¯æŒçš„æ¨¡å‹"""
    print("ğŸ” æŸ¥è¯¢AIHubMixæ”¯æŒçš„æ¨¡å‹åˆ—è¡¨")
    print("=" * 60)
    
    if not Config.AIHUBMIX_API_KEY:
        print("âŒ AIHubMix APIå¯†é’¥æœªé…ç½®")
        return
    
    print(f"ğŸ”‘ APIå¯†é’¥: {Config.AIHUBMIX_API_KEY[:8]}...")
    print(f"ğŸŒ APIç«¯ç‚¹: {Config.AIHUBMIX_BASE_URL}")
    print()
    
    try:
        # AIHubMixé€šå¸¸å…¼å®¹OpenAIæ ¼å¼
        url = f"{Config.AIHUBMIX_BASE_URL.rstrip('/')}/models"
        headers = {
            "Authorization": f"Bearer {Config.AIHUBMIX_API_KEY}",
            "Content-Type": "application/json"
        }
        
        print(f"ğŸ“¡ è°ƒç”¨API: {url}")
        response = requests.get(url, headers=headers, timeout=15)
        
        print(f"ğŸ“Š çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            
            if 'data' in data and isinstance(data['data'], list):
                models = [model['id'] for model in data['data']]
                print(f"âœ… æŸ¥è¯¢æˆåŠŸï¼Œå…± {len(models)} ä¸ªæ¨¡å‹:")
                
                # æŒ‰ç±»å‹åˆ†ç»„ï¼ˆåŸºäºæ¨¡å‹åç§°ï¼‰
                gpt_models = [m for m in models if 'gpt' in m.lower()]
                claude_models = [m for m in models if 'claude' in m.lower()]
                gemini_models = [m for m in models if 'gemini' in m.lower()]
                llama_models = [m for m in models if 'llama' in m.lower()]
                other_models = [m for m in models if m not in gpt_models + claude_models + gemini_models + llama_models]
                
                if gpt_models:
                    print(f"\nğŸ“‚ GPTæ¨¡å‹ ({len(gpt_models)} ä¸ª):")
                    for i, model in enumerate(sorted(gpt_models), 1):
                        print(f"  {i:2d}. {model}")
                
                if claude_models:
                    print(f"\nğŸ“‚ Claudeæ¨¡å‹ ({len(claude_models)} ä¸ª):")
                    for i, model in enumerate(sorted(claude_models), 1):
                        print(f"  {i:2d}. {model}")
                
                if gemini_models:
                    print(f"\nğŸ“‚ Geminiæ¨¡å‹ ({len(gemini_models)} ä¸ª):")
                    for i, model in enumerate(sorted(gemini_models), 1):
                        print(f"  {i:2d}. {model}")
                
                if llama_models:
                    print(f"\nğŸ“‚ LLaMAæ¨¡å‹ ({len(llama_models)} ä¸ª):")
                    for i, model in enumerate(sorted(llama_models), 1):
                        print(f"  {i:2d}. {model}")
                
                if other_models:
                    print(f"\nğŸ“‚ å…¶ä»–æ¨¡å‹ ({len(other_models)} ä¸ª):")
                    for i, model in enumerate(sorted(other_models), 1):
                        print(f"  {i:2d}. {model}")
                        
            elif 'models' in data:
                # å…¼å®¹å…¶ä»–æ ¼å¼
                models = data['models']
                print(f"âœ… æŸ¥è¯¢æˆåŠŸï¼Œå…± {len(models)} ä¸ªæ¨¡å‹:")
                for i, model in enumerate(sorted(models), 1):
                    print(f"  {i:2d}. {model}")
            else:
                print("ğŸ“‹ å®Œæ•´å“åº”æ•°æ®:")
                import json
                print(json.dumps(data, ensure_ascii=False, indent=2))
                
        elif response.status_code == 401:
            print("âŒ è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
        elif response.status_code == 404:
            print("âŒ ç«¯ç‚¹ä¸å­˜åœ¨ï¼ŒAIHubMixå¯èƒ½ä¸æ”¯æŒæ¨¡å‹åˆ—è¡¨API")
            print("ğŸ’¡ æ˜¾ç¤ºå¸¸è§çš„ç¬¬ä¸‰æ–¹å¹³å°æ”¯æŒçš„æ¨¡å‹:")
            show_common_models()
        else:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {response.status_code}")
            if response.text:
                print(f"å“åº”å†…å®¹: {response.text[:300]}")
            print("ğŸ’¡ æ˜¾ç¤ºå¸¸è§çš„ç¬¬ä¸‰æ–¹å¹³å°æ”¯æŒçš„æ¨¡å‹:")
            show_common_models()
                
    except requests.exceptions.Timeout:
        print("âŒ è¯·æ±‚è¶…æ—¶")
        print("ğŸ’¡ æ˜¾ç¤ºå¸¸è§çš„ç¬¬ä¸‰æ–¹å¹³å°æ”¯æŒçš„æ¨¡å‹:")
        show_common_models()
    except requests.exceptions.RequestException as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")
        print("ğŸ’¡ æ˜¾ç¤ºå¸¸è§çš„ç¬¬ä¸‰æ–¹å¹³å°æ”¯æŒçš„æ¨¡å‹:")
        show_common_models()
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¼‚å¸¸: {e}")

def show_common_models():
    """æ˜¾ç¤ºç¬¬ä¸‰æ–¹å¹³å°å¸¸è§çš„æ¨¡å‹"""
    print()
    print("ğŸ“‚ ç¬¬ä¸‰æ–¹å¹³å°å¸¸è§æ¨¡å‹:")
    
    common_models = [
        # GPTç³»åˆ—
        "gpt-3.5-turbo",
        "gpt-3.5-turbo-16k",
        "gpt-4",
        "gpt-4-turbo",
        "gpt-4-32k",
        
        # Claudeç³»åˆ—
        "claude-3-sonnet",
        "claude-3-opus",
        "claude-3-haiku",
        "claude-2.1",
        "claude-2",
        "claude-instant-1.2",
        
        # Googleç³»åˆ—
        "gemini-pro",
        "gemini-pro-vision", 
        "palm-2",
        
        # å¼€æºæ¨¡å‹
        "llama-2-7b-chat",
        "llama-2-13b-chat",
        "llama-2-70b-chat",
        "vicuna-7b",
        "vicuna-13b",
    ]
    
    for i, model in enumerate(common_models, 1):
        print(f"  {i:2d}. {model}")
    
    print(f"\nğŸ¯ å½“å‰é»˜è®¤æ¨¡å‹: {Config.DEFAULT_MODELS['aihubmix']}")
    
    # æä¾›æµ‹è¯•å»ºè®®
    print(f"\nğŸ’¡ å»ºè®®æµ‹è¯•:")
    print("python tests/test_single_platform.py aihubmix -m \"ä½ å¥½\"")

if __name__ == "__main__":
    get_aihubmix_models()